# Deep Learning-Based Intrusion Detection With Adversaries

本文研究了基于深度学习的NSL-KDD数据集入侵检测攻击算法的性能。实验验证了神经网络在入侵检测系统中的脆弱性。探讨了个体特征在生成对抗性例子中的作用。在此基础上，讨论了攻击方法的可行性和适用性。

基于操作逻辑，IDS可以被视为两大类：（1）基于特征的IDS，将流量与已知威胁的特征数据库进行比较；（2）基于异常的IDS，根据活动的行为检查流量。

Szegedy等人。[6]  2014年首次揭示了一个有趣的发现，即深层神经网络容易受到对抗性例子的攻击。他们还通过使用Broyden-FletcherGoldfarb-Shanno（LBFGS）优化算法的盒子约束有限记忆近似成功地生成了对抗性例子。自那以后，这一发现的深远影响引发了学术界和工业界对发展对抗性攻击和研究其防御机制的广泛兴趣。为了缓解LBFGS方法的高计算成本，Goodfellow等人。[7]  提出了快速梯度符号法（FGSM）。FGSM基于损失函数相对于输入图像的梯度产生对抗性扰动，从而通过反向传播提高计算效率。Kurakinet  al.[8]通过对多次迭代运行更精细的优化（较小的变化）扩展了快速梯度符号法。Papernot等人。[9]  通过计算前向导数来创建对抗显著性映射，前向导数用于识别要向目标类扰动的输入特征。Moosavi Dezwooli等人。[10]  提出了一种从原始输入到对抗实例决策边界的最近距离的求取方法。Carlini和Wagner[11]提出了三种新的基于梯度的攻击算法（L2、L∞和L0），它们在最小扰动量下获得的对抗成功率方面比所有已知的方法都更有效。他们的L2attack使用了一个基于logits的目标函数，它不同于所有现有的L2attack，并且通过改变变量避免了box约束。它们的L∞和l0基于l2攻击，并根据不同的距离度量进行定制。现有文献主要讨论了在典型的计算机视觉任务（如识别）中愚弄深层神经网络的艺术，并使用标准图像数据集（如MNIST[5]）证明了它们的有效性。

#### 对抗性例子的目标：有目标，无目标

#### 关于目标模型的知识：白盒，黑盒。大多数为白盒攻击，转移到黑盒。得益于对抗攻击样本的可移植性。

#### 距离度量：三种范数。

###### L0距离意味着在两个样本之间扰动的特征的数量。

###### L2距离测量x和x0之间的标准欧氏（均方根）距离。当对许多样品引入微小的变化时，大的L0偏差可以保持小的L2。

###### L∞距离测量任何特征的最大变化。大的L∞不一定会导致大的L2。L∞完全是由具有足够小的扰动的一组大特征中对单个特征的显著改变引起的。类似地，考虑到单个特征显著改变而其他特征保持不变的情况，一个大的L∞可能与一个小的L0共存。

#### 攻击算法：

###### A. FAST GRADIENT SIGN METHOD (FGSM)：快速梯度符号法

###### Goodfellow 等人，快速梯度符号法根据L∞距离度量对网络进行优化。虽然它的速度很快，但它的设计主要不是为了寻找最佳的对抗实例。Kurakin等人通过对多次迭代运行更精细的优化（较小的变化），扩展了快速梯度符号法。在每次迭代中，都会剪裁像素值，以避免每个像素上的较大更改。

###### 迭代梯度符号的结果优于快速梯度符号。为了攻击具有增强能力的特定类，提出了另一种FGSM方案，选择最不可能的预测类，并尝试最大化交叉熵损失。这种方法称为迭代类方法。作为另一种变体，目标类梯度符号方法（TGSM）可以扩展到更一般的情况。目标类可以是任意期望的类。

###### B.JACOBIAN-BASED SALIENCY MAP ATTACK (JSMA)

###### 计算雅可比矩阵，x的输入特性可以被识别出来，x的输入特性对输出做出了最重要的改变。当一些小的输入偏差触发大的输出变化时，使用那些最有影响的特征。

###### C. DEEPFOOL

###### DeepFool算法来寻找从原始输入到对抗实例决策边界的最近距离。DeepFool是一种针对L2距离度量优化的无目标攻击技术。为了克服高维非线性，提出了一种线性逼近迭代攻击方法。从仿射分类器出发，发现仿射分类器的最小扰动是到分离仿射超平面F={x:wTx+b=0}的距离。

###### D. CW ATTACK

###### 一种有针对性的攻击来击败防御蒸馏。

#### 评价方法：

###### A. NSL-KDD DATASET数据集介绍

###### 用于测试入侵检测算法的最常用数据集之一是KDD'99数据集，该数据集来自DARPA'98  IDS评估程序。研究人员发现了KDD'99数据集的两个主要缺陷[12]：对于训练和测试数据来说是一个巨大的缺陷；由于数据集的不平衡，某些类型的攻击很容易被发现。NSL-KDD数据集[14]是KDD'99数据集的改进版本，它从两个方面克服了KDD'99数据集的局限性：从训练和测试数据中删除所有多余的记录；根据KDD'99数据集中的记录的分类难易程度重新平衡，使标杆学习算法更加合理和现实。

###### NSL-KDD数据集中的每条记录都有41个特征。

###### 这些特性分为三大类：

###### •basic features 基本特性是与连接信息（如主机、端口、使用的服务和协议）相关的特性。

###### •traffic features 流量特征是指在窗口间隔期间作为一个集合计算的特征。它们进一步分类为基于同一主机的聚合和基于同一服务的聚合。KDD'99和NSL-KDD数据集的一个显著区别是，后者的时间窗口被最后100个连接的连接窗口所c替代。

###### •content features 内容特征是从分组数据或有效载荷中提取的，它们与特定应用程序或使用的协议的内容相关。

###### NSL-KDD数据集中的每个记录都被标记为普通攻击或特定攻击类别。训练数据包含23个traffic classes ，包括22个攻击类和一个正常类。测试数据包含38个traffic classes，包括来自训练数据的21个攻击类、16个新的攻击类和一个普通类。

###### ONE-HOT ENCODING（独热编码）

###### NORMALIZATION（标准化）

###### CLASSIFICATION OF ATTACK TYPES（攻击类型分类）

NSL-KDD数据集中的攻击类型分为四大类：拒绝服务（DOS）、探测、远程到本地（R2L）和用户到根（U2R）攻击：

•DOS攻击是针对可用性或阻止合法用户访问信息或服务的攻击。

•探测攻击是指通过扫描或探测网络来收集信息的攻击。

•R2L攻击是试图获得对本地计算机的未经授权的远程访问的攻击。

•U2R攻击是试图访问正常用户帐户并利用系统中的漏洞提升权限的攻击。

分类后，将39种攻击类型转化为4种攻击标签。

###### PRE-PROCESSED DATASET SUMMARY（数据集预处理）

对攻击类型进行一次热编码、规范化和分类之后，该问题被转换为5类分类问题，其中5个标签为“Normal”、“DOS”、“Probe”、“R2L”和“U2R”，122个数字特征在0和1之间。数据集有训练集和测试集。

#### METHODOLOGY（方法论）

###### holdout cross-validation method（交叉验证）

本文只考虑敌方已知目标深层神经网络的白盒攻击。我们使用多层感知器（MLPs）作为入侵检测的神经网络架构。mlp由两层隐层构成，每层包含256个神经单元。每个隐藏单元的激活函数都是线性单元（ReLU），为了正则化，在每个隐藏层之后采用了漏失率为0.4的dropout层。在训练网络时，通过移除具有任意概率的单个单元，应用缺失层来控制拟合。在logits层之后使用softmax层作为分类器的输出。优化程序、batchSize和在线学习分别是ADAM、128和0.001。采用交叉熵代价函数作为损失函数，通过训练使损失最小化。首先，我们将训练数据输入到深度神经网络中，并允许足够多的时间段获得训练良好的深度神经网络。深层神经网络被用作攻击的目标以及我们评估的基准。然后，我们实现了四种攻击算法，并分别使用它们从基于深度神经网络的测试数据集中生成对手样本。最后，我们评估了在测试数据集和对抗性示例中分类的性能。

###### METRICS（性能指标）

性能评估基于以下指标进行：

•真阳性（TP）-正确分类为攻击的攻击数据。

•假阳性（FP）-错误分类为攻击的正常数据。

•真阴性（TN）-正确分类为正常的正常数据。

•假阴性（FN）-错误分类为正常的攻击数据。

![image-20200413163247737](C:\Users\LEO\AppData\Roaming\Typora\typora-user-images\image-20200413163247737.png)

#### 结果和讨论

###### CLEAN DATA（干净数据集）

ROC曲线通常用于二值分类以研究分类器的输出。为了将ROC曲线和ROC区域扩展到多类或多标签分类，需要对输出进行二值化。每个标签可以绘制一条ROC曲线，但也可以通过将标签指示符矩阵的每个元素视为二进制预测（微观平均）来绘制ROC曲线。多类分类的另一个评价指标是宏观平均，使每个标签的分类具有同等的权重。

![image-20200413164243133](C:\Users\LEO\AppData\Roaming\Typora\typora-user-images\image-20200413164243133.png)

######  JSMA ATTACKS（JSMA攻击）

ATTACKS FROM SCRATCH（从零开始）

ATTACKS FROM ORIGINAL SAMPLES

###### FGSM ATTACKS

UNTARGETED ATTACKS

###### LEAST-LIKELY ATTACKS

###### RANDOM-TARGET ATTACKS

###### DEEPFOOL ATTACKS

###### CW ATTACKS

#### DISCUSSION

CW攻击的破坏力似乎比其他三次攻击要小。不过，据报道，它对一些最先进的防御措施更为有力。

与其他三种攻击相比，JSMA攻击更不平衡地使用特征生成敌对示例。特别是，CW攻击倾向于不加区别地使用所有功能，即使它们为L2。考虑到这样一个事实，攻击者通常很容易操纵一小部分特性而不是一大部分特性。这样，JSMA攻击对攻击者更有吸引力。



######         本文对基于深度学习的入侵检测领域的最新攻击算法进行了评价。我们发现，这些攻击算法最初是为了愚弄基于深度学习的图像分类器而提出的，在入侵检测领域表现出不同程度的有效性。我们确定了攻击算法的不同特征使用模式。在实践中，对手拥有有限的资源和能力来操纵特征。因此，在大多数情况下，对对手来说，更改一组大的功能是不太实际的。由于JSMA攻击倾向于大量使用一组有限的特性，因此它们在可用性和适用性方面对对手来说相对更具吸引力。我们还注意到，各特征在被敌方干扰的概率方面具有不同程度的显著性。最常用的特征表明它们有助于提高基于深度学习的入侵检测的安全性，因此在检测和防御方面值得更多的关注和更好的保护。由于可转移性对于blackbox攻击通常是至关重要的，因此未来的工作将集中在基于深度学习的入侵检测中对手示例的可转移性上。它将从三个维度进行研究：1）同一神经网络内不同输入训练的可传递性；2）不同神经网络间的可传递性；3）著名的传统机器学习算法（即随机森林、支持向量机、决策树）与深层神经网络间的可传递性。