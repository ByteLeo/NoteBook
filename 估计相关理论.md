## 1 相关理论

### 1.1 全概率公式

全概率公式为概率论中的重要公式，它将对一复杂事件A的概率求解问题转化为了在不同情况下发生的简单事件的概率的求和问题。

如果事件B1、B2、B3…Bn 构成一个完备事件组，即它们两两互不相容，其和为全集；并且P（Bi)大于0，则对任一事件A有



![img](https:////upload-images.jianshu.io/upload_images/1531909-deb04a4f3e70c373.png?imageMogr2/auto-orient/strip|imageView2/2/w/356/format/webp)

特别地，对于任意两随机事件A和B，有如下成立：



![img](https:////upload-images.jianshu.io/upload_images/1531909-dd887b3770d02550.png?imageMogr2/auto-orient/strip|imageView2/2/w/246/format/webp)

### 1.2 先验概率

先验概率（prior probability）是指根据以往经验和分析得到的概率。

> 意思是说我们人有一个常识,比如骰子,我们都知道概率是1/6,而且无数次重复实验也表明是这个数,这是一种我们人的常识,也是我们在不知道任何情况下必然会说出的一个值.而所谓的先验概率是我们人在未知条件下对事件发生可能性猜测的数学表示!

### 1.3 后验概率

事情已经发生，要求这件事情发生的原因是由某个因素引起的可能性的大小

### 1.4 举个例子

举一个简单的例子：一口袋里有3只红球、2只白球，采用不放回方式摸取，求：

⑴ 第一次摸到红球（记作A）的概率；

⑵ 第二次摸到红球（记作B）的概率；

⑶ 已知第二次摸到了红球，求第一次摸到的是红球的概率。

解：

⑴ P(A)=3/5，这就是先验概率；

⑵ P(B)=P(A)P(B|A)+P(A`)P(B|A`)=3/5

⑶ P(A|B)=P(A)P(B|A)/P(B)=1/2，这就是后验概率。

## 2 最大似然估计

最大似然估计的核心思想是：找到参数θ的一个估计值，使得当前样本出现的可能性最大，俗话说是“谁大像谁”。

假设有一组独立同分布(i.i.d)的随机变量X，给定一个概率分布D，假设其概率密度函数为f，以及一个分布的参数θ，从这组样本中抽出x1,x2,⋯,xn，那么通过参数θ的模型f产生上面样本的概率为：



![img](https:////upload-images.jianshu.io/upload_images/1531909-cfdcdf74786d61e5.png?imageMogr2/auto-orient/strip|imageView2/2/w/401/format/webp)

最大似然估计会寻找关于θ 的最可能的值，即在所有可能的 θ 取值中，寻找一个值使这个采样的“可能性”最大化！
 因为是”模型已定，参数未知”，此时我们是根据样本采样x1,x2,⋯,xn取估计参数θ，定义似然函数为：



![img](https:////upload-images.jianshu.io/upload_images/1531909-270884ae363b4fee.png?imageMogr2/auto-orient/strip|imageView2/2/w/417/format/webp)

实际使用中，因为f(xi|θ)一般比较小，而且n往往会比较大，连乘容易造成浮点运算下溢。所以一般我们用对数似然函数：



![img](https:////upload-images.jianshu.io/upload_images/1531909-b8a6d0465fe0aac2.png?imageMogr2/auto-orient/strip|imageView2/2/w/845/format/webp)



根据前面的描述，总结一下求最大释然估计值的步骤：
 1.写似然函数
 2.一般对似然函数取对数，并将对数似然函数整理
 3.对数似然函数求导，令导数为0，求得似然方程
 4.根据似然方程求解，得到的参数即为所求估计值

## 3 贝叶斯估计

统计学里有两个大的流派，一个是频率派，一个是贝叶斯派。时至今日，这两派还未就各自的观点达成统一。我们前面提到的最大似然估计就是频率派的典型思路，接下来再看看贝叶斯派的思路，到底跟频率派估计有何不同。
 先来看几个相关的小公式：
 两个随机变量x,y的联合概率p(x,y)的乘法公式：



![img](https:////upload-images.jianshu.io/upload_images/1531909-197b88c2b132827e.png?imageMogr2/auto-orient/strip|imageView2/2/w/287/format/webp)



如果x,y是独立随机变量，上面的式子可以表示为:



![img](https:////upload-images.jianshu.io/upload_images/1531909-702f8aba3bbf3175.png?imageMogr2/auto-orient/strip|imageView2/2/w/245/format/webp)


 那么条件概率就可以表示为：

![img](https:////upload-images.jianshu.io/upload_images/1531909-e207a5ccecb7d6ce.png?imageMogr2/auto-orient/strip|imageView2/2/w/265/format/webp)


 对于一个完备事件组y1,y2,⋯,yn，可以使用全概率公式：

![img](https:////upload-images.jianshu.io/upload_images/1531909-c624cdaf0fb0e878.png?imageMogr2/auto-orient/strip|imageView2/2/w/326/format/webp)



由以上这些，可以得出贝叶斯公式：



![img](https:////upload-images.jianshu.io/upload_images/1531909-1d48f25c2a612936.png?imageMogr2/auto-orient/strip|imageView2/2/w/262/format/webp)

其中，p(yi|x)是后验概率。p(x|yi)是条件概率，或者说似然概率，这个概率一般都可以通过历史数据统计得出。而p(yi)是先验概率，一般也是根据历史数据统计得出或者认为给定的，贝叶斯里的先验概率，就是指p(yi)。对于p(x)，我们前面提到可以用全概率公式计算得出，但是在贝叶斯公式里面我们一般不care这个概率，因为我们往往只需要求出最大后验概率而不需要求出最大后验的具体值。

2,3部分内容来自：
 [最大似然估计MLE与贝叶斯估计](https://blog.csdn.net/bitcarmanlee/article/details/52201858)

## 4 区别

- 理解1：

> 最大似然估计和贝叶斯估计最大区别便在于估计的参数不同，最大似然估计要估计的参数θ被当作是固定形式的一个未知变量，然后我们结合真实数据通过最大化似然函数来求解这个固定形式的未知变量！

> 贝叶斯估计则是将参数视为是有某种已知先验分布的随机变量，意思便是这个参数他不是一个固定的未知数，而是符合一定先验分布如：随机变量θ符合正态分布等！那么在贝叶斯估计中除了类条件概率密度p(x|w)符合一定的先验分布，参数θ也符合一定的先验分布。我们通过贝叶斯规则将参数的先验分布转化成后验分布进行求解！

- 理解2：

> 简而言之，最大似然估计认为参数的所有可能取值都是一样可能的。而贝叶斯方法认为还存在一个先验估计，有些取值更有可能，有些取值更加没有可能。

- 理解3：

> 最大似然是对点估计，贝叶斯推断是对分布估计。
>  即，假设求解参数θ，最大似然是求出最有可能的θ值，而贝叶斯推断则是求解θ的分布。

> 在公式上，贝叶斯推断还引入了先验，通过先验和似然来求解后验分布，而最大似然直接使用似然函数，通过最大化其来求解。



作者：致Great
链接：https://www.jianshu.com/p/ead99acd6437
来源：简书
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。